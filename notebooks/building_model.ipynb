{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import division\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "\n",
    "# ignore deprecation warnings in sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_dir=os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from data.multilabel import multilabel_sample_dataframe, multilabel_train_test_split\n",
    "from features.SparseInteractions import SparseInteractions\n",
    "from models.metrics import multi_multi_log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.16.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "First, we'll load the entire training data set available from DrivenData. In order to make this notebook run, you will need to:\n",
    "\n",
    "Sign up for an account on DrivenData\n",
    "Join the Box-plots for education competition\n",
    "Download the competition data to the data folder in this repository. Files should be named TrainingSet.csv and TestSet.csv.\n",
    "Enjoy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_training_data = os.path.join(os.pardir, 'data', 'TrainingData.csv')\n",
    "path_to_test_data = os.path.join(os.pardir,'data','TestData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_to_training_data, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 400277 entries, 134338 to 415831\n",
      "Data columns (total 25 columns):\n",
      "Function                  400277 non-null object\n",
      "Use                       400277 non-null object\n",
      "Sharing                   400277 non-null object\n",
      "Reporting                 400277 non-null object\n",
      "Student_Type              400277 non-null object\n",
      "Position_Type             400277 non-null object\n",
      "Object_Type               400277 non-null object\n",
      "Pre_K                     400277 non-null object\n",
      "Operating_Status          400277 non-null object\n",
      "Object_Description        375493 non-null object\n",
      "Text_2                    88217 non-null object\n",
      "SubFund_Description       306855 non-null object\n",
      "Job_Title_Description     292743 non-null object\n",
      "Text_3                    109152 non-null object\n",
      "Text_4                    53746 non-null object\n",
      "Sub_Object_Description    91603 non-null object\n",
      "Location_Description      162054 non-null object\n",
      "FTE                       126071 non-null float64\n",
      "Function_Description      342195 non-null object\n",
      "Facility_or_Department    53886 non-null object\n",
      "Position_Extra            264764 non-null object\n",
      "Total                     395722 non-null float64\n",
      "Program_Description       304660 non-null object\n",
      "Fund_Description          202877 non-null object\n",
      "Text_1                    292285 non-null object\n",
      "dtypes: float64(2), object(23)\n",
      "memory usage: 79.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-18b278c59fd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dt' is not defined"
     ]
    }
   ],
   "source": [
    "len(dt.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our purpose and computational efficiency, we will sample down to 10,000 rows from 400,277rows so that it's easy to quick to run our analysis. We will also create dummy variables for our labels and split our sampel dataset into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LABELS = ['Function',\n",
    "          'Use',\n",
    "          'Sharing',\n",
    "          'Reporting',\n",
    "          'Student_Type',\n",
    "          'Position_Type',\n",
    "          'Object_Type', \n",
    "          'Pre_K',\n",
    "          'Operating_Status']\n",
    "NON_LABELS = [c for c in df.columns if c not in LABELS]\n",
    "SAMPLE_SIZE = 40000\n",
    "sampling = multilabel_sample_dataframe(df, \n",
    "                            pd.get_dummies(df[LABELS]),\n",
    "                            size = SAMPLE_SIZE,\n",
    "                            min_count=25,\n",
    "                            seed=43)\n",
    "\n",
    "dummy_labels = pd.get_dummies(sampling[LABELS])\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(sampling[NON_LABELS],\n",
    "                                                               dummy_labels,\n",
    "                                                               0.2,\n",
    "                                                               min_count=3,\n",
    "                                                               seed=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create preprocessing toolsÂ¶\n",
    "We need tools to preprocess our text and numeric data. We'll create those tools here. The combine_text_columns function will take a DataFrame of text columns and return a single series where all of the text in the columns has been joined together.\n",
    "\n",
    "We'll then create FunctionTransformer objects that select our text and numeric data from the dataframe.\n",
    "\n",
    "Finally, we create a custom scoring method that uses the multi_multi_log_loss function that is the evaluation metric for the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_COLUMNS = ['FTE', 'Total']\n",
    "\n",
    "def combine_text_columns(data_frame, to_drop = NUMERIC_COLUMNS + LABELS):\n",
    "    \"\"\" Takes the dataset as read in, drops the non-feature, non-text columns and\n",
    "        then combines all of the text columns into a single vector that has all of\n",
    "        the text for a row.\n",
    "        \n",
    "        :param data_frame: The data as read in with read_csv (no preprocessing necessary)\n",
    "        :param to_drop (optional): Removes the numeric and label columns by default.\n",
    "    \"\"\"\n",
    "    # drop non-text columns that are in the df\n",
    "    to_drop = set(to_drop) & set(data_frame.columns.tolist())\n",
    "    text_data = data_frame.drop(to_drop, axis=1)\n",
    "    \n",
    "    # replace NaN with Blanks\n",
    "    text_data.fillna(\"\", inplace=True)\n",
    "    \n",
    "    # joins all of the text items in a row (axis=1) with a space in between\n",
    "    return text_data.apply(lambda x: \" \".join(x), axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134338       Teacher-Elementary        KINDERGARTEN  KIN...\n",
       "206341    CONTRACTOR SERVICES BOND EXPENDITURES BUILDING...\n",
       "326408    Personal Services - Teachers   TCHER 2ND GRADE...\n",
       "364634    EMPLOYEE BENEFITS TEACHER SUBS GENERAL FUND Te...\n",
       "47683     TEACHER COVERAGE FOR TEACHER TEACHER SUBS GENE...\n",
       "229958    CONTRA BENEFITS  GENERAL FUND Custodian - PT -...\n",
       "417668    EDUCATIONAL SPECIAL EDUCATION INSTRUCTION LOCA...\n",
       "126378    EMPLOYEE BENEFITS  GENERAL FUND Sub Manager, F...\n",
       "275539    EMPLOYEE BENEFITS  GENERAL FUND Teacher, Eleme...\n",
       "85262     EMPLOYEE BENEFITS TEACHER SUBS GENERAL FUND Te...\n",
       "304569    EQUIPMENT *  Support Services - Administration...\n",
       "330504    SUPPLIES  PRIMARY GRADES PROGRAM       INSTRUC...\n",
       "84272     Personal Services - Teachers   TCHER P E (ELEM...\n",
       "64760     Regular *  Special Instruction    Certificated...\n",
       "21870     OTHER PERSONAL SERVICES          SUB TEACHER A...\n",
       "18698     Salaries And Wages For Substitute Professional...\n",
       "169454    SUPPLIES                         TEACHER, TITL...\n",
       "169914    Regular * ADM/PROF Operation and Maintenance o...\n",
       "189701    ELECTRICITY OPERATIONS - UTILITIES GENERAL FUN...\n",
       "43727     Non-Certificated Travel Reimbursement  Support...\n",
       "5614      Purchased Services  Support Services--Pupils  ...\n",
       "291539    SALARIES OF PART TIME EMPLOYEE TEACHER SUBS GE...\n",
       "307038    Regular * TEACHER Special Instruction TCHR, SC...\n",
       "27645     BONUSES                          ESE CLERICAL ...\n",
       "126388    Personal Services - Substitute Teachers Certif...\n",
       "14962     Personal Services - Teachers   TCHER ENGLISH (...\n",
       "84040     EQUIPMENT *  Support Services - Instructional ...\n",
       "61639     EMPLOYEE BENEFITS  GENERAL FUND Teacher, Short...\n",
       "266302    EMPLOYEE BENEFITS  GENERAL FUND Teacher, Eleme...\n",
       "225768    Extra Duty Pay/Overtime For Support Personnel ...\n",
       "                                ...                        \n",
       "333748    Regular * TEACHERSUP Support Services--Pupils ...\n",
       "292626    Extra Duty Pay/Overtime For Support Personnel ...\n",
       "343458    SALARIES OF PART TIME EMPLOYEE TEACHER SUBS GE...\n",
       "128261    SALARIES OF REGULAR EMPLOYEES SEVERE DISABILIT...\n",
       "186318    SALARIES OF REGULAR EMPLOYEES  GENERAL FUND Te...\n",
       "210652    Personal Services - Substitute Teachers Non-Ce...\n",
       "340354    EMPLOYEE BENEFITS  FEDERAL GDPG FUND - FY  ELA...\n",
       "435205    EMPLOYER PD MED CONTRIBUTION  STATE AND LOCAL ...\n",
       "174827    SALARIES OF PART TIME EMPLOYEE  FEDERAL GDPG F...\n",
       "277504    CONTRA BENEFITS  GENERAL FUND Teacher, Element...\n",
       "248062    Travel And Subsistence - Employee Only      Tr...\n",
       "70455     CLASSROOM TEACHER                TEACHER, SOC ...\n",
       "203453    IN-COUNTY TRAVEL                     School  S...\n",
       "58170     Personal Services - Substitute Teachers Certif...\n",
       "72072     Personal Services - Assistant Principals   ASS...\n",
       "68311     ADDITIONAL/EXTRA DUTY PAY/STIP MATH/SCIENCE FE...\n",
       "225892    SALARIES OF REGULAR EMPLOYEES  GENERAL FUND Te...\n",
       "446383    Other Pupil Transportation Services  Support S...\n",
       "155111    Extra Duty Pay/Overtime For Support Personnel ...\n",
       "278248    SUPPLIES  PRIMARY GRADES PROGRAM       INSTRUC...\n",
       "397424    ADDITIONAL/EXTRA DUTY PAY/STIP  BOND Secondary...\n",
       "375092    Personal Services - Substitute Teachers Certif...\n",
       "220181    Salaries Or Wages For Support Personnel  Child...\n",
       "307423    Other Awards and Prizes  Support Services - In...\n",
       "46691     ADDITIONAL/EXTRA DUTY PAY/STIP MATH/SCIENCE FE...\n",
       "109283    WORKSHOP PARTICIPANT             CURRICULUM RE...\n",
       "102430    SALARIES OF PART TIME EMPLOYEE  FEDERAL GDPG F...\n",
       "413949       School Liaison       PARENT/TITLE I Misc Sc...\n",
       "433672    EMPLOYEE BENEFITS EDUCATIONAL RESOURCE SERVICE...\n",
       "415831    Salaries And Wages For Substitute Professional...\n",
       "Length: 400277, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_text_columns(df, to_drop=NUMERIC_COLUMNS + LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "get_text_data = FunctionTransformer(combine_text_columns, validate=False)\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FTE</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NaN</td>\n",
       "      <td>653.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2153.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-8291.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>NaN</td>\n",
       "      <td>618.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>0.71</td>\n",
       "      <td>21747.666875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FTE         Total\n",
       "38    NaN    653.460000\n",
       "70    NaN   2153.530000\n",
       "198   NaN  -8291.860000\n",
       "209   NaN    618.290000\n",
       "614  0.71  21747.666875"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text_data.fit_transform(sampling.head(5))\n",
    "get_numeric_data.fit_transform(sampling.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.scorer import make_scorer\n",
    "log_loss_scorer = make_scorer(multi_multi_log_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL PIPELINE\n",
    "Now we'll train the final pipeline from the course that takes text and numeric data, does the necessary preprocessing, and trains the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logloss score of trained pipeline:  2.1864848617308343\n",
      "CPU times: user 16min 39s, sys: 8.58 s, total: 16min 47s\n",
      "Wall time: 4min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# set a reasonable number of features before adding interactions\n",
    "chi_k = 300\n",
    "\n",
    "# create the pipeline object\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', HashingVectorizer(token_pattern=TOKENS_ALPHANUMERIC,alternate_sign=False, norm=None, binary=False,ngram_range=(1, 2))),\n",
    "                    ('dim_red', SelectKBest(chi2, chi_k))\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('int', SparseInteractions(degree=2)),\n",
    "        ('scale', MaxAbsScaler()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "# fit the pipeline to our training data\n",
    "pl.fit(X_train, y_train.values)\n",
    "\n",
    "# print the score of our trained pipeline on our test set\n",
    "print(\"Logloss score of trained pipeline: \", log_loss_scorer(pl, X_test, y_test.values))\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_holdout_data=os.path.join (os.pardir, 'data', 'TestData.csv')\n",
    "\n",
    "# Load holdout data\n",
    "#holdout = pd.read_csv(path_to_holdout_data, index_col=0)\n",
    "holdout = pd.read_csv(path_to_holdout_data, index_col=0)\n",
    "# Make predictions\n",
    "predictions = pl.predict_proba(holdout)\n",
    "#predictions = pl.predict_proba(holdout)\n",
    "\n",
    "# Format correctly in new DataFrame: prediction_df\n",
    "prediction_df = pd.DataFrame(columns = pd.get_dummies(df[LABELS]).columns,\n",
    "                            index=holdout.index,\n",
    "                            data=predictions)\n",
    "\n",
    "#prediction_df = pd.DataFrame(columns=pd.get_dummies(df[LABELS]).columns,\n",
    "#                             index=holdout.index,\n",
    "#                             data=predictions)\n",
    "\n",
    "\n",
    "# Save prediction_df to csv called \"predictions.csv\"\n",
    "prediction_df.to_csv(\"predictions.csv\")\n",
    "#prediction_df.to_csv(\"predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-d02548c944e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "prediction_df.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
